---
title: "NWS Flood Data Loop Build"
output: html_document
date: "2023-12-28"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(here)
library(tidyverse)
library(stringr)
library(fs)

```

# Notes
##(12-28-2023)

This is a building and testing document. I am working on a loop which will clean and load flood data from the NWS.

NOTE: Flooding definitions change a lot over the years! BUT, I am in coding mode, so I should finish this, only with a limited number of years.
  NEW PLAN: Create a version of the function which just gets a count of all the different events by year! This will allow you to code things up, and avoid having to find older versions of the documentation.

TO DO:

1. I need to create code to get a list of the files I want to import
  - Only certain years
  - Only "detail" files
2. I need to take these files one at a time, clean them
3. Merge them
  - This is sort of easy - there is a map function.

# Function Work

## Get File List

For certain years - (you didn't do this with the QCEW data)
For 'details' files

```{r}

# Define the function
get_filepaths <- function(base_path, start_year, end_year) {
  
  # Define the path to your files
  nws_path <- here(base_path)

  # Define the range of years
  nws_years <- start_year:end_year

  # Create a regex pattern to match filenames with the specified years
  year_pattern <- paste(nws_years, collapse = "|")
  filename_pattern <- str_glue("StormEvents_details-ftp_v1\\.0_d({year_pattern}).*\\.csv$")
  
  # List and filter files based on the pattern
  nws_files <- dir_ls(path = nws_path, regexp = filename_pattern)

  # Modify filenames
  modified_filenames <- lapply(nws_files, function(filename) {
    # Extract the last part of the filename (after the last '/')
    last_part <- basename(filename)

    # Duplicate and append this part to the original filename
    str_c(filename, "/", last_part)
  })

  return(modified_filenames)
}

```

```{r}

nws_files <- get_filepaths('data/storm_events/11-5', start_year = 1975, end_year = 2023)

```



## Clean and Count Function

```{r}

event_count <- function(file_name){
  read.csv(file_name) %>% 
    filter(CZ_TYPE == "C") %>% 
    group_by(EVENT_TYPE) %>%
    summarise(
      count = n(),
      year = min(YEAR)
    )
}

```

### Testing

```{r eval=FALSE}

test_df <-  read.csv(here("data/storm_events/11-5/StormEvents_details-ftp_v1.0_d2020_c20230927.csv/StormEvents_details-ftp_v1.0_d2020_c20230927.csv")) %>% 
    filter(CZ_TYPE == "C") %>% 
    group_by(EVENT_TYPE) %>%
    summarise(
      count = n(),
      year = min(YEAR)
    )

```


### Map 1

```{r}

events_df <- map_dfr(nws_files, event_count)

```

# Tableau Version

```{r eval=FALSE}

write_csv(events_df, here("data/storm_events/test/events_75-23.csv"))

```

